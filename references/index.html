
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://insper.github.io/rl/references/">
      
      
        <link rel="prev" href="../projects/projeto_final/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.10">
    
    
      
        <title>Referências - Reinforcement Learning</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.0d440cfe.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#referencias-e-ferramentas" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Reinforcement Learning" class="md-header__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reinforcement Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Referências
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Reinforcement Learning" class="md-nav__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Reinforcement Learning
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../goals/" class="md-nav__link">
        Ementa
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../plan/" class="md-nav__link">
        Plano
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../assessment/" class="md-nav__link">
        Avaliação
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          Aulas
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Aulas
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
          Introdução
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          Introdução
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/01_introduction/" class="md-nav__link">
        Apresentação da disciplina
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/02_problem_solving/" class="md-nav__link">
        Revisão sobre busca em espaço de estados
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/03_games/" class="md-nav__link">
        Revisão sobre algoritmos de busca competitivos e jogos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/03_review/" class="md-nav__link">
        Revisão das implementações
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
      
      
      
        <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
          Q-Learning and Sarsa
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Q-Learning and Sarsa
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/04_toolings_envs/" class="md-nav__link">
        Ferramentas e ambientes para aprendizagem por reforço
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/05_q_learning/" class="md-nav__link">
        Algoritmo Q-Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/05_x_hyperparameters/" class="md-nav__link">
        Hiperparâmetros em Q-Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/05_x_sarsa/" class="md-nav__link">
        Algoritmo SARSA: abordagem on-policy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/05_xx_comments/" class="md-nav__link">
        Comentários sobre as implementações do Q-Learning e Sarsa
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
      
      
      
        <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
          Ambientes e metodologias
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          Ambientes e metodologias
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/11_evaluation/" class="md-nav__link">
        Como avaliar o desempenho de um agente?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/06_non_determ/" class="md-nav__link">
        Ambientes não-determinísticos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/06_non_determ_comments/" class="md-nav__link">
        Comentários sobre as entregas referentes ao ambiente Frozen Lake.
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/09_more_complex/" class="md-nav__link">
        Implementando um agente para lidar com um ambiente um pouco mais complexo
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
      
      
      
        <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
          Deep Q-Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_4">
          <span class="md-nav__icon md-icon"></span>
          Deep Q-Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/15_deep_q_learning/" class="md-nav__link">
        Deep Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/15_deep_q_learning_lunar_lander/" class="md-nav__link">
        Lunar Lander Project
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/16_double_deep_q_learning/" class="md-nav__link">
        Double Deep Q-Learning
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
          Policy Optimization
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_5">
          <span class="md-nav__icon md-icon"></span>
          Policy Optimization
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classes/17_reinforce/" class="md-nav__link">
        Algoritmo Reinforce
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          Projetos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Projetos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../projects/projeto_intermediario/" class="md-nav__link">
        Projeto intermediário
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../projects/projeto_final/" class="md-nav__link">
        Projeto Final
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Referências
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Referências
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#livros" class="md-nav__link">
    Livros
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#artigos" class="md-nav__link">
    Artigos
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementacoes-e-tutoriais" class="md-nav__link">
    Implementações e tutoriais
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ferramentas" class="md-nav__link">
    Ferramentas
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#livros" class="md-nav__link">
    Livros
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#artigos" class="md-nav__link">
    Artigos
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementacoes-e-tutoriais" class="md-nav__link">
    Implementações e tutoriais
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ferramentas" class="md-nav__link">
    Ferramentas
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="referencias-e-ferramentas">Referências e ferramentas</h1>
<p>Nesta página estão listadas as principais referências e ferramentas utilizadas nesta disciplina.</p>
<h2 id="livros">Livros</h2>
<ol>
<li>
<p>Sutton, R. S., &amp; Barto, A. G. (2018). <a href="https://mitpress.mit.edu/9780262039246/reinforcement-learning/">Reinforcement learning: An introduction (2<sup>nd</sup> ed.)</a>. The MIT Press. </p>
</li>
<li>
<p>Stefano V. Albrecht, Filippos Christianos, and Lukas Schäfer. <a href="https://www.marl-book.com/">Multi-Agent Reinforcement Learning: Foundations and Modern Approaches</a>. MIT Press, 2024.</p>
</li>
<li>
<p>Mitchell, T. (1997). Reinforcement Learning in <a href="https://www.cs.cmu.edu/~tom/files/MachineLearningTomMitchell.pdf">Machine Learning</a>. McGraw-Hill.</p>
</li>
<li>
<p>NORVIG, P.; RUSSELL, S., <a href="https://aima.cs.berkeley.edu/">Inteligência Artificial</a>, 3ª ed., Campus Elsevier, 2013</p>
</li>
</ol>
<h2 id="artigos">Artigos</h2>
<ol>
<li>Watkins, C.J.C.H., Dayan, P. <a href="https://link.springer.com/article/10.1007/BF00992698">Q-Learning</a>. Mach Learn 8, 279–292 (1992). <a href="https://doi.org/10.1007/BF00992698">https://doi.org/10.1007/BF00992698</a></li>
<li>
<p>Williams, R.J. <a href="https://doi.org/10.1007/BF00992696">Simple statistical gradient-following algorithms for connectionist reinforcement learning</a>. Machine Learning 8, 229–256
(1992). <a href="https://doi.org/10.1007/BF00992696">https://doi.org/10.1007/BF00992696</a>.</p>
</li>
<li>
<p>Mnih V, Kavukcuoglu K, Silver D, Graves A, Antonoglou I, Wierstra D, Riedmiller M. <a href="https://arxiv.org/abs/1312.5602">Playing atari with deep reinforcement learning</a>. arXiv preprint arXiv:1312.5602. 2013 Dec 19.</p>
</li>
<li>
<p>Mnih, V., Kavukcuoglu, K., Silver, D. et al. <a href="https://www.nature.com/articles/nature14236">Human-level control through deep reinforcement learning</a>. Nature 518, 529–533 (2015). <a href="https://doi.org/10.1038/nature14236">https://doi.org/10.1038/nature14236</a></p>
</li>
<li>
<p>Schulman J, Levine S, Abbeel P, Jordan M, Moritz P. <a href="https://arxiv.org/abs/1502.05477">Trust region policy optimization</a>. In International conference on machine learning 2015 Jun 1 (pp. 1889-1897). PMLR.</p>
</li>
<li>
<p>van Hasselt, H., Guez, A. and Silver, D. 2016. Deep Reinforcement Learning with Double Q-Learning. Proceedings of the AAAI Conference on Artificial Intelligence. 30, 1 (Mar. 2016). DOI: <a href="https://doi.org/10.1609/aaai.v30i1.10295">https://doi.org/10.1609/aaai.v30i1.10295</a>.</p>
</li>
<li>
<p>Schulman J, Wolski F, Dhariwal P, Radford A, Klimov O. <a href="https://arxiv.org/abs/1707.06347">Proximal policy optimization algorithms</a>. arXiv preprint arXiv:1707.06347. 2017 Jul 20.</p>
</li>
<li>
<p>Silver D. et al. <a href="https://www.science.org/doi/epdf/10.1126/science.aar6404">A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play</a>. Science 362,1140-1144 (2018). DOI:10.1126/science.aar6404.</p>
</li>
<li>
<p>Silver D., Singh S., Precup D., Sutton R. <a href="https://www.sciencedirect.com/science/article/pii/S0004370221000862">Reward is enough</a>, Artificial Intelligence, Volume 299, 2021, <a href="https://doi.org/10.1016/j.artint.2021.103535">https://doi.org/10.1016/j.artint.2021.103535</a>.</p>
</li>
<li>
<p>M. Mehdi Afsar, Trafford Crump, and Behrouz Far. 2022. <a href="https://doi.org/10.1145/3543846">Reinforcement Learning based Recommender Systems: A Survey</a>. ACM Comput. Surv. 55, 7, Article 145 (July 2023), 38 pages. <a href="https://doi.org/10.1145/3543846">https://doi.org/10.1145/3543846</a></p>
</li>
<li>
<p>Shuo Sun, Rundong Wang, and Bo An. 2023. <a href="https://doi.org/10.1145/3582560">Reinforcement Learning for Quantitative Trading</a>. ACM Trans. Intell. Syst. Technol. 14, 3, Article 44 (June 2023), 29 pages. <a href="https://doi.org/10.1145/3582560">https://doi.org/10.1145/3582560</a></p>
</li>
<li>
<p>Andrej Karpathy. Deep Reinforcement Learning: Pong from Pixels. Disponível em <a href="http://karpathy.github.io/2016/05/31/rl/">http://karpathy.github.io/2016/05/31/rl/</a>. Acessado a última vez em 30 de abril de 2023. </p>
</li>
<li>
<p>Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann Stable-Baselines3: Reliable Reinforcement Learning Implementations. Journal of Machine Learning Research, 2021. <a href="http://jmlr.org/papers/v22/20-1364.html">http://jmlr.org/papers/v22/20-1364.html</a>.</p>
</li>
</ol>
<h2 id="implementacoes-e-tutoriais">Implementações e tutoriais</h2>
<ol>
<li>
<p>Deep Reinforcement Learning from OpenAI. Disponível em <a href="https://spinningup.openai.com/en/latest/index.html">https://spinningup.openai.com/en/latest/index.html</a>. Acessado a última vez em 30 de abril de 2023.</p>
</li>
<li>
<p>Brockman G, Cheung V, Pettersson L, Schneider J, Schulman J, Tang J, Zaremba W. <a href="https://arxiv.org/abs/1606.01540">Openai gym</a>. arXiv preprint arXiv:1606.01540. 2016 Jun 5.</p>
</li>
<li>
<p>Raffin R., Hill A., Gleave A., Kanervisto A., Ernestus M., Dormann N. <a href="http://jmlr.org/papers/v22/20-1364.html">Stable-Baselines3: Reliable Reinforcement Learning Implementations</a>. Journal of Machine Learning Research, 2021. <a href="http://jmlr.org/papers/v22/20-1364.html">http://jmlr.org/papers/v22/20-1364.html</a>.</p>
</li>
<li>
<p>Andrej Karpathy. Deep Reinforcement Learning: Pong from Pixels. Disponível em <a href="http://karpathy.github.io/2016/05/31/rl/">http://karpathy.github.io/2016/05/31/rl/</a>. Acessado a última vez em 30 de abril de 2023.</p>
</li>
<li>
<p>Deep Reinforcement Learning from OpenAI. Disponível em <a href="https://spinningup.openai.com/en/latest/index.html">https://spinningup.openai.com/en/latest/index.html</a>. Acessado a última vez em 30 de abril de 2023.</p>
</li>
<li>
<p>The 37 Implementation Details of Proximal Policy Optimization. Disponível <a href="https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/">https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/</a>. Último acesso em maio de 2023.</p>
</li>
<li>
<p>Understanding Proximal Policy Optimization (Schulman et al., 2017). Disponível <a href="https://blog.tylertaewook.com/post/proximal-policy-optimization">https://blog.tylertaewook.com/post/proximal-policy-optimization</a>. Último acesso em maio de 2023.</p>
</li>
<li>
<p>Simonini, T. Proximal Policy Optimization (PPO). Unit 8, of the Deep Reinforcement Learning Class with Hugging Face. Disponível em <a href="https://huggingface.co/blog/deep-rl-ppo">https://huggingface.co/blog/deep-rl-ppo</a>. Último acesso em maio de 2023.</p>
</li>
<li>
<p>Deep Reinforcement Learning Class with Hugging Face. Disponível em <a href="https://huggingface.co/learn/deep-rl-course/unit0/introduction">https://huggingface.co/learn/deep-rl-course/unit0/introduction</a>. Último acesso em fevereiro de 2024.</p>
</li>
</ol>
<h2 id="ferramentas">Ferramentas</h2>
<ol>
<li><a href="https://farama.org/">The Farama Foundation</a>: this group is responsible for maintaining the <a href="https://gymnasium.farama.org/">Gymnasium</a> and <a href="https://pettingzoo.farama.org/">PettingZoo</a> projects. </li>
<li><a href="https://github.com/Kaggle/kaggle-environments">Kaggle Environments Project</a>.</li>
<li>How to use <a href="https://gymnasium.farama.org/">Gymnasium API</a>: a Python library for single agent reinforcement learning.</li>
<li><a href="https://github.com/Farama-Foundation/SuperSuit">SuperSuit</a>: wrappers for RL environments. </li>
<li><a href="https://openai.com/blog/emergent-tool-use/">Worldgen</a>: Emergent tool use from multi-agent interaction.</li>
<li><a href="http://highway-env.farama.org/">Highway envs</a>.</li>
<li><a href="https://tianshou.readthedocs.io/en/master/">Tianshou</a> is a reinforcement learning platform based on pure PyTorch.</li>
<li><a href="https://unity.com/products/machine-learning-agents">Unity Machine Learning Agents</a>.</li>
<li><a href="https://github.com/shashist/recsys-rl">Reinforcement learning for Recommendation Systems</a>.</li>
<li><a href="https://flatland.aicrowd.com/intro.html">FlatLand</a>. </li>
<li><a href="https://pypi.org/project/DSSE/">Drone Swarm Search Environment</a>.</li>
<li><a href="https://marllib.readthedocs.io/en/latest/handbook/env.html#">MARLlib environments</a>.</li>
<li><a href="https://agents.inf.ed.ac.uk/blog/new-environments-algorithm-multiagent-rl/">Multi-Robot Warehouse Environments</a>.</li>
</ol>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">April 10, 2024</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.db81ec45.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.6df46069.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.0.0/js-yaml.min.js"></script>
      
        <script src="../js/markdown-enhancer.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>