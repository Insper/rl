# RLHF

* Pretraining a language model (LM),
* gathering data and training a reward model, and
* fine-tuning the LM with reinforcement learning.

 the design space of options in RLHF training are not thoroughly explored.



## References

* https://huggingface.co/blog/rlhf

* https://www.youtube.com/watch?v=T_X4XFwKX8k v√≠deo sobre RLHF

* https://arxiv.org/pdf/1909.08593: Fine-Tuning Language Models from Human Preferences

* https://github.com/allenai/RL4LMs: RL4LMs: A modular RL library to fine-tune language models to human preferences





