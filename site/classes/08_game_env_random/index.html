
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://insper.github.io/rl/classes/08_game_env_random/">
      
      
        <link rel="prev" href="../07_game_env/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.10">
    
    
      
        <title>Using RL in a competitive environment with random behavior - Reinforcement Learning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0d440cfe.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#using-rl-in-a-competitive-environment-with-random-behavior" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Reinforcement Learning" class="md-header__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reinforcement Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Using RL in a competitive environment with random behavior
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/Insper/rl/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Reinforcement Learning
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Reinforcement Learning" class="md-nav__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Reinforcement Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Insper/rl/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Reinforcement Learning
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../goals/" class="md-nav__link">
        Goals
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../plan/" class="md-nav__link">
        Plan
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../assessment/" class="md-nav__link">
        Student Assessment
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          Classes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Classes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_introduction/" class="md-nav__link">
        Introduction to Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_problem_solving/" class="md-nav__link">
        Problem-solving searching review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_games/" class="md-nav__link">
        Adversarial search and games review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_review/" class="md-nav__link">
        Implementations review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_toolings_envs/" class="md-nav__link">
        Reinforcement Learning Tooling and Environments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_q_learning/" class="md-nav__link">
        Q-Learning Algorithm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_x_hyperparameters/" class="md-nav__link">
        Hyperparameters in Q-Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_x_sarsa/" class="md-nav__link">
        SARSA Algorithm: on-policy approach
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_xx_comments/" class="md-nav__link">
        Comments about Q-Learning and Sarsa implementation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_non_determ/" class="md-nav__link">
        Using RL in non-deterministic environments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_non_determ_comments/" class="md-nav__link">
        Comments about the Frozen Lake implementations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_game_env/" class="md-nav__link">
        Using RL in a competitive environment
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Using RL in a competitive environment with random behavior
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Using RL in a competitive environment with random behavior
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#jogador-de-blackjack" class="md-nav__link">
    Jogador de BlackJack
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algoritmo-e-hiperparametros-utilizados-para-o-treinamento" class="md-nav__link">
    Algoritmo e hiperparâmetros utilizados para o treinamento
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rubrica-de-avaliacao" class="md-nav__link">
    Rubrica de avaliação
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deadline" class="md-nav__link">
    Deadline
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#jogador-de-blackjack" class="md-nav__link">
    Jogador de BlackJack
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algoritmo-e-hiperparametros-utilizados-para-o-treinamento" class="md-nav__link">
    Algoritmo e hiperparâmetros utilizados para o treinamento
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rubrica-de-avaliacao" class="md-nav__link">
    Rubrica de avaliação
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deadline" class="md-nav__link">
    Deadline
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  



<h1 id="using-rl-in-a-competitive-environment-with-random-behavior">Using RL in a competitive environment with random behavior</h1>
<p>The goal of this activity is to implement an agent to play Blackjack using Q-Learning or Sarsa algorithms and show the results.</p>
<h2 id="jogador-de-blackjack">Jogador de BlackJack</h2>
<p>A biblioteca Gymnasium possui um ambiente que simula um jogo de <a href="https://gymnasium.farama.org/environments/toy_text/blackjack/">BlackJack (<em>Blackjack-v1</em>)</a>. A documentação deste ambiente está disponível neste link <a href="https://gymnasium.farama.org/environments/toy_text/blackjack/">https://gymnasium.farama.org/environments/toy_text/blackjack/</a>. </p>
<p>Além da documentação, você tem acesso a duas implementações:</p>
<ul>
<li><a href="https://github.com/Insper/rl_code/blob/main/src/part_04/BlackJack_Manual.py">BlackJack_Manual.py</a>: onde você pode jogar várias partidas de BlackJack e entender a representação de estado adotada pelo ambiente;</li>
<li><a href="https://github.com/Insper/rl_code/blob/main/src/part_04/BlackJack_Agent.py">BlackJack_Agent.py</a>: que tem uma implementação de agente que aprende a jogar BlackJack usando aprendizagem por reforço, e;</li>
<li><a href="https://github.com/Insper/rl_code/blob/main/src/part_04/QLearning_BlackJack.py">QLearning_Blackjack.py</a>: uma versão do algoritmo QLearning com adição de um método para tratamento dos estados do ambiente BlackJack. </li>
</ul>
<p>Atividades propostas: </p>
<ul>
<li>
<p>Execute diversas vezes o arquivo <a href="https://github.com/Insper/rl_code/blob/main/src/part_04/BlackJack_Manual.py">BlackJack_Manual.py</a> para entender como o ambiente funciona. Principalmente como a representação do espaço de estados funciona. </p>
</li>
<li>
<p>Execute o arquivo <a href="https://github.com/Insper/rl_code/blob/main/src/part_04/BlackJack_Agent.py">BlackJack_Agent.py</a> com o objetivo de criar uma nova q-table.</p>
</li>
</ul>
<p>Perguntas: </p>
<ul>
<li>
<p>Como podemos obter um agente com o melhor desempenho possível? É possível criar um agente que ganha ou empata em no mínimo 85% dos jogos? Se sim, quais são os hiperparâmetros para este agente? Se não, qual é o melhor resultado encontrado? </p>
</li>
<li>
<p>É possível plotar a q-table? Este plot de q-table seria útil para um jogador de BlackJack real? Justifique a sua resposta. </p>
</li>
</ul>
<p>Entrega: </p>
<ul>
<li>
<p>você também deve adicionar a sua implementação no diretório raiz do projeto no Github Classroom: <a href="https://classroom.github.com/a/Qe2Tawio">https://classroom.github.com/a/Qe2Tawio</a>.</p>
</li>
<li>
<p>para a sua implementação estar completa você deve adicionar um script para validação na q-table no ambiente. </p>
</li>
<li>
<p>criar um arquivo README.md informando os hiperparâmetros utilizados para o treinamento. </p>
</li>
<li>
<p>(critério para A) usar o algoritmo Sarsa para este problema. Neste caso você deve fazer algo similar ao que está implementado no arquivo <a href="https://github.com/Insper/rl_code/blob/main/src/part_04/QLearning_BlackJack.py">QLearning_Blackjack.py</a>.   </p>
</li>
<li>
<p>(critério para A+) apresentar um gráfico que resume a q-table, ou seja, que resume o que fazer em cada jogada. Comente também se é possível utilizar esta q-table em uma situação real ou não. </p>
</li>
</ul>
<h2 id="algoritmo-e-hiperparametros-utilizados-para-o-treinamento">Algoritmo e hiperparâmetros utilizados para o treinamento</h2>
<table>
<thead>
<tr>
<th align="left">Atributo</th>
<th align="center">Valor</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Algoritmo</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">alpha</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">gamma</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">epsilon</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">epsilon_dec</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">epsilon_min</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">qtd_episodios</td>
<td align="center"></td>
</tr>
</tbody>
</table>
<h2 id="rubrica-de-avaliacao">Rubrica de avaliação</h2>
<ul>
<li>
<p>Deixou de entregar um dos artefatos: q-table, implementação na forma de arquivo python ou arquivo README.md atualizado com os hiperparâmetros: igual a <strong>Insuficiente (I)</strong> - nota 2. </p>
</li>
<li>
<p>Entregou todos os artefatos mencionados acima e o desempenho do agente passou de 85% então nota igual a <strong>8.0</strong>.</p>
</li>
<li>
<p>Entregou a implementação do algoritmo Sarsa com adição de um método para tratamento dos estados do ambiente BlackJack <span class="arithmatex">\(\rightarrow\)</span> <strong>nota = 9.0</strong>. </p>
</li>
<li>
<p>Entregou o gráfico que resume a q-table e explicou se é possível utilizar tal informação em uma situação real ou não então nota igual a <strong>10.00</strong>.</p>
</li>
</ul>
<h2 id="deadline">Deadline</h2>
<p>O deadline para a entrega desta atividade é 21 de março de 2023 às 23:30 horas. Este trabalho deve ser feito em grupo - o mesmo grupo da implementação do tic-tac-toe usando reinforcement learning. </p>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">March 17, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.db81ec45.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6df46069.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.0.0/js-yaml.min.js"></script>
      
        <script src="../../js/markdown-enhancer.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>