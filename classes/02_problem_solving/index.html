
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://insper.github.io/rl/classes/02_problem_solving/">
      
      
        <link rel="prev" href="../01_introduction/">
      
      
        <link rel="next" href="../03_games/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.10">
    
    
      
        <title>Problem-solving searching review - Reinforcement Learning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0d440cfe.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#problem-solving-searching-review" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Reinforcement Learning" class="md-header__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reinforcement Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Problem-solving searching review
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/Insper/rl/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Reinforcement Learning
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Reinforcement Learning" class="md-nav__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Reinforcement Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Insper/rl/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Reinforcement Learning
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../goals/" class="md-nav__link">
        Goals
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../plan/" class="md-nav__link">
        Plan
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../assessment/" class="md-nav__link">
        Student Assessment
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          Classes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Classes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_introduction/" class="md-nav__link">
        Introduction to Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Problem-solving searching review
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Problem-solving searching review
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#algorithms" class="md-nav__link">
    Algorithms
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a-taxi-driver-agent-without-reinforcement-learning" class="md-nav__link">
    A Taxi Driver Agent without Reinforcement Learning
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#before-starting-the-implementation" class="md-nav__link">
    Before starting the implementation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#requirements" class="md-nav__link">
    Requirements
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hints" class="md-nav__link">
    Hints
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#delivery" class="md-nav__link">
    Delivery
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_games/" class="md-nav__link">
        Adversarial search and games review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_review/" class="md-nav__link">
        Implementations review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_toolings_envs/" class="md-nav__link">
        Reinforcement Learning Tooling and Environments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_q_learning/" class="md-nav__link">
        Q-Learning Algorithm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_x_hyperparameters/" class="md-nav__link">
        Hyperparameters in Q-Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_x_sarsa/" class="md-nav__link">
        SARSA Algorithm: on-policy approach
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_xx_comments/" class="md-nav__link">
        Comments about Q-Learning and Sarsa implementation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_non_determ/" class="md-nav__link">
        Using RL in non-deterministic environments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_non_determ_comments/" class="md-nav__link">
        Comments about the Frozen Lake implementations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_game_env/" class="md-nav__link">
        Using RL in a competitive environment
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#algorithms" class="md-nav__link">
    Algorithms
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a-taxi-driver-agent-without-reinforcement-learning" class="md-nav__link">
    A Taxi Driver Agent without Reinforcement Learning
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#before-starting-the-implementation" class="md-nav__link">
    Before starting the implementation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#requirements" class="md-nav__link">
    Requirements
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hints" class="md-nav__link">
    Hints
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#delivery" class="md-nav__link">
    Delivery
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  



<h1 id="problem-solving-searching-review">Problem-solving searching review</h1>
<p>Problem-solving search is a process of finding a solution to a problem by systematically exploring possible solutions and eliminating those that don't meet the requirements. It is used in artificial intelligence to solve complex problems that require a combination of data, and reasoning. The goal of a problem-solving search is to find the optimal solution, which is the solution that best meets the desired criteria. </p>
<p>The search process involves representing the problem as a <strong>state space</strong>, defining the <strong>initial state</strong> and the <strong>goal state</strong>, and then using algorithms to explore possible solutions by moving from one state to another until the goal state is reached. The choice of algorithm depends on the specific problem, the size of the state space, and the desired time and memory complexity of the solution.</p>
<h2 id="algorithms">Algorithms</h2>
<p>There are several types of algorithms used in a problem-solving search:</p>
<ul>
<li>
<p><strong>Uninformed Search Algorithms</strong>: These algorithms do not use any information about the problem and search blindly through the state space. Examples include Breadth-First Search (BFS), Depth-First Search (DFS), and Depth-Limited Search.</p>
</li>
<li>
<p><strong>Informed Search Algorithms</strong>: These algorithms use information about the problem, such as heuristics, to guide the search process and make it more efficient. Examples include A* Search, and Greedy Search.</p>
</li>
<li>
<p><strong>Local Search Algorithms</strong>: These algorithms are used to find a local optimum solution, rather than a globally optimum solution. They are often used in optimization problems where finding the global optimum is too time-consuming or computationally expensive. Examples include Hill Climbing, Simulated Annealing, and Genetic Algorithms.</p>
</li>
</ul>
<p>Each of these algorithms has its own strengths and weaknesses, and the choice of algorithm depends on the specific problem, the size of the state space, and the desired time and memory complexity of the solution.</p>
<h2 id="references">References</h2>
<p>Some references that maybe be useful:</p>
<ul>
<li>
<p><a href="https://ocw.mit.edu/courses/6-034-artificial-intelligence-fall-2010/resources/lecture-4-search-depth-first-hill-climbing-beam/">Lecture 4: Search: Depth-First, Hill Climbing, Beam from MIT Open Courseware</a></p>
</li>
<li>
<p><a href="https://ocw.mit.edu/courses/6-034-artificial-intelligence-fall-2010/resources/lecture-5-search-optimal-branch-and-bound-a/">Lecture 5: Search: Optimal, Branch and Bound, A*</a></p>
</li>
</ul>
<h2 id="a-taxi-driver-agent-without-reinforcement-learning">A Taxi Driver Agent without Reinforcement Learning</h2>
<p>In this exercise, you must implement a <em>taxi driver</em> agent that can pick up a passenger at one point and leave this passenger at another point considering a specific map. An example of a map is presented below: </p>
<p><img src="img/mapa_00.png"></p>
<p>This map is a very simple one. This map has only 3 columns and 3 rows, without any barrier. The taxi is in position [0,0], the passenger is in position [1,2], and the passenger must be taken at [2,0].</p>
<p>We know that the taxi agent can execute the following actions:</p>
<ul>
<li><strong>go down</strong>: The result of executing this action is to move the taxi to one row down;</li>
<li><strong>go up</strong>: The result of this action is to move the taxi one row up;</li>
<li><strong>go right</strong>: The result of this action is to move the taxi one column right;</li>
<li><strong>go left</strong>: The result of this action is to move the taxi onde column left;</li>
<li><strong>pick up passenger</strong>: The taxi only can perform this action if it is at the same position as the passenger and the passenger is not inside the taxi. After the execution of this action, the passenger will be inside the taxi;</li>
<li><strong>leave passenger</strong>: The agent only can perform this action if the passenger is inside the taxi. The result of performing this action is to leave the passenger at the same position as the taxi. </li>
</ul>
<p>A sub-set of space state for this problem can be represented as follow: </p>
<p><img src="img/spaces.png"></p>
<p>A possible solution for this problem is: </p>
<div class="highlight"><pre><span></span><code>right; down; right; right; pick_up; down; left; left; leave
</code></pre></div>
<p><strong>How can we implement a piece of software which finds an optimal solution for this problem considering any initial state?</strong> </p>
<p>This software must be able to handle different configurations with different dimensions. For example, the images below show different initial states:</p>
<p>This image has barriers:</p>
<p><img src="img/mapa_01.png"></p>
<p>This state represents a situation where the passenger is inside the taxi:</p>
<p><img src="img/mapa_02.png"> </p>
<p>This state has a bigger number of barriers: </p>
<p><img src="img/mapa_03.png"></p>
<h2 id="before-starting-the-implementation">Before starting the implementation</h2>
<p>Before starting the implementation, you must answer some questions:</p>
<ul>
<li>
<p>What is relevant to represent in each state in the world? Which data structures are good to represent these states? Which is the meaning of each variable? </p>
</li>
<li>
<p>Which are the actions that the agent can perform? How do those actions change the states? </p>
</li>
<li>
<p>Which search algorithm is good to solve this problem? Is any heuristics necessary? </p>
</li>
<li>
<p>Which are the limits of your solution? Is this solution able to solve any map? </p>
</li>
</ul>
<h2 id="requirements">Requirements</h2>
<ul>
<li>
<p>Each group must deliver an implementation, the test files using <code>pytest</code> and a README.md file that explains how this implementation works.</p>
</li>
<li>
<p>Your implementation must receive the map configuration as a text file.</p>
</li>
<li>
<p>The test files must consider the scenarios described above and also the maps illustrated below:  </p>
</li>
</ul>
<p><img src="img/mapa_04.png"></p>
<p><img src="img/mapa_05.png"></p>
<h2 id="hints">Hints</h2>
<ul>
<li>You must define the data structure to represent each state. Use only variables that are relevant to solve this problem. If you use unnecessary attributes this will increase the search space.</li>
<li>You must define how the actions will change the state representation. Try to avoid generating useless states - this also may increase the search space.</li>
<li>Start your implementation with the simplest configurations. </li>
<li>There are a lot of implementations of uninformed and informed search algorithms available on the Internet. Try to reuse one of them.</li>
</ul>
<h2 id="delivery">Delivery</h2>
<ul>
<li>
<p>This exercise must be done by a group of maximum 3 students. </p>
</li>
<li>
<p>The <strong>deadline is 02/21/2023 20:00 -0300.</strong></p>
</li>
<li>
<p>The implementation must be delivered through <em>Github classroom</em>. This is the link <a href="https://classroom.github.com/a/bFRDDmcO">https://classroom.github.com/a/bFRDDmcO</a>. </p>
</li>
</ul>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 22, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.db81ec45.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6df46069.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.0.0/js-yaml.min.js"></script>
      
        <script src="../../js/markdown-enhancer.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>