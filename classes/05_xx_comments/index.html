
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://insper.github.io/rl/classes/05_xx_comments/">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.10">
    
    
      
        <title>Comments about Q-Learning and Sarsa implementation - Reinforcement Learning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0d440cfe.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#comments-about-q-learning-and-sarsa-implementation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Reinforcement Learning" class="md-header__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reinforcement Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Comments about Q-Learning and Sarsa implementation
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Reinforcement Learning" class="md-nav__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Reinforcement Learning
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../goals/" class="md-nav__link">
        Ementa
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../plan/" class="md-nav__link">
        Plano
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../assessment/" class="md-nav__link">
        Avalia√ß√£o
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          Aulas
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Aulas
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
      
      
      
        <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
          Introdu√ß√£o
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          Introdu√ß√£o
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_introduction/" class="md-nav__link">
        Apresenta√ß√£o da disciplina
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_problem_solving/" class="md-nav__link">
        Revis√£o sobre busca em espa√ßo de estados
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_games/" class="md-nav__link">
        Revis√£o sobre algoritmos de busca competitivos e jogos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_review/" class="md-nav__link">
        Revis√£o das implementa√ß√µes
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        Refer√™ncias
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#qlearning-vs-sarsa-vantagens-e-desvantagens" class="md-nav__link">
    QLearning vs  Sarsa - Vantagens e Desvantagens üìåÔ∏è
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#valores-utilizados-com-mais-frequencia" class="md-nav__link">
    Valores utilizados com mais frequ√™ncia
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="comments-about-q-learning-and-sarsa-implementation">Comments about Q-Learning and Sarsa implementation</h1>
<p><em>Answers from Carlos Dip, Andr√© Tavernaro and Let√≠cia.</em></p>
<ul>
<li>Which algorithm has the best results for the taxi-driver environment? </li>
</ul>
<p>In my implementation, the SARSA algorithm converged slightly faster than Q-Learning. In simulations, they seemed to perform similarly, with no big differences in pathing.</p>
<ul>
<li>Which algorithm has the best results for the Cliff Walking environment? </li>
</ul>
<p>In my implementation, the QLearning algorithm converged a bit faster than SARSA. In the simulation, there was a big difference in behavior. Since SARSA learns while taking into account random actions, it tries to steer clear of the cliff in this scenario. This happens because, during its training, there was a random chance it would fall despite it being a known bad action. This means the Q-Table essentially learns to be sacred of costly mistakes.</p>
<ul>
<li>Try to explain the results. Why one algorithm is better than another? </li>
</ul>
<p>It seems like SARSA is more interesting when you are looking for a risk-minimizing strategy. It is more careful and looks into making less strictly efficient decisions preferring to minimize risks. Q-Learning, on the other hand, is much more direct. It maximizes rewards, regardless of risks. I would not say either algorithm is better, they are just more suited to certain situations. In a non-deterministic environment, this risk-averse behavior might be more interesting, although perhaps a hybrid of risk aversion and pure efficiency.</p>
<ul>
<li>Do a small research about Sarsa algorithm to understand its cons and pros. </li>
</ul>
<p>SARSA is an example of an on-policy Reinforcement Learning algorithm. This means that the policy it follows during learning is the same as the one it uses to update its policy. In this case, we use an epsilon-greedy policy, meaning we take the best-known option, with an epsilon randomness factor chance of taking a random action instead. This means SARSA learns a near-optimal policy instead of an optimal one, which can be bad if a problem requires the optimal solution. Since SARSA tends to avoid mistakes while training, it is more advantageous to use it in scenarios where these mistakes are costly, such as training using real-world data, like a robot or self-driving car.</p>
<p>Q-Learning in the Cliff walking world:</p>
<p><img src="figures/QLearning-Cliff.png" alt="Q-Learning in the Cliff walking world" style="height: 200px;"/></p>
<p>Sarsa in the Cliff walking world:</p>
<p><img src="figures/Sarsa-Cliff.png" alt="Sarsa in the Cliff walking world" style="height: 200px;"/></p>
<h2 id="qlearning-vs-sarsa-vantagens-e-desvantagens">QLearning vs  Sarsa - Vantagens e Desvantagens üìåÔ∏è</h2>
<ul>
<li><code>QLearning</code></li>
</ul>
<div class="arithmatex">\[Q(S_t, A_t) = Q(S_t, A_t) + \alpha[R_{t+1} + \gamma max(Q(S_{t+1}, a)) - Q(S_t, A_t) ]\]</div>
<p>Algor√≠timo que busca encontrar a melhor a√ß√£o a ser tomada, dado um estado atual. </p>
<p>√â considerao um algor√≠itmo <strong>off-policy</strong>, pois a melhor a√ß√£o √© escolhida para a atualiza√ß√£o da <strong>q_table</strong> mesmo que essa a√ß√£o n√£o seja aplicada nessa ocasi√£o (fator de aleatoriedade na tomada de uma a√ß√£o - <strong>Explore</strong>).</p>
<p>Como o QLearning aprende com a "pol√≠tica √≥tima", ele √© considerado um algor√≠timo mais "agressivo. Ou seja, No exemplo do ambiente CliffWalking o QL seguir√° o caminho mais curto, pois esse √© o caminho √≥timo, mesmo que haja risco maior de queda.</p>
<ul>
<li><code>Sarsa</code></li>
</ul>
<div class="arithmatex">\[Q(S_t, A_t) = Q(S_t, A_t) + \alpha[R_{t+1} + \gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t) ]\]</div>
<p>Como √© poss√≠vel observar pela formula, o algor√≠timo SARSA aprende com uma pol√≠tica "quase √≥tima". Um agente treinado com o algor√≠timo SARSA interage com o ambiente atualizando <strong>q_table</strong> com base nas a√ß√µes efetivamente tomadas. Quando o problema envolve achar a solu√ß√£o √≥tima ou quando o n√∫mero m√≠nimo de a√ß√µes deve ser tomada na resolu√ß√£o do problema, o algor√≠timo SARSA pode n√£o se apresentar como a melhor escolha.</p>
<h2 id="valores-utilizados-com-mais-frequencia">Valores utilizados com mais frequ√™ncia</h2>
<div class="highlight"><pre><span></span><code><span class="n">sarsa</span> <span class="o">=</span> <span class="n">Sarsa</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">epsilon_min</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon_dec</span><span class="o">=</span><span class="mf">0.99999</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</code></pre></div>
<p>Algu√©m testou?</p>
<div class="highlight"><pre><span></span><code><span class="n">sarsa</span> <span class="o">=</span> <span class="n">Sarsa</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">epsilon_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">epsilon_dec</span><span class="o">=</span><span class="mf">0.99999</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</code></pre></div>
<p>o que acontece? </p>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">March 9, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.db81ec45.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6df46069.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.0.0/js-yaml.min.js"></script>
      
        <script src="../../js/markdown-enhancer.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>