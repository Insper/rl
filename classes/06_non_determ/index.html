
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://insper.github.io/rl/classes/06_non_determ/">
      
      
        <link rel="prev" href="../05_xx_comments/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.10">
    
    
      
        <title>Using RL in non-deterministic environments - Reinforcement Learning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0d440cfe.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#using-rl-in-non-deterministic-environments" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Reinforcement Learning" class="md-header__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reinforcement Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Using RL in non-deterministic environments
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/Insper/rl/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Reinforcement Learning
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Reinforcement Learning" class="md-nav__button md-logo" aria-label="Reinforcement Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Reinforcement Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Insper/rl/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Reinforcement Learning
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../goals/" class="md-nav__link">
        Goals
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../plan/" class="md-nav__link">
        Plan
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../assessment/" class="md-nav__link">
        Student Assessment
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          Classes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Classes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_introduction/" class="md-nav__link">
        Introduction to Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_problem_solving/" class="md-nav__link">
        Problem-solving searching review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_games/" class="md-nav__link">
        Adversarial search and games review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_review/" class="md-nav__link">
        Implementations review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_toolings_envs/" class="md-nav__link">
        Reinforcement Learning Tooling and Environments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_q_learning/" class="md-nav__link">
        Q-Learning Algorithm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_x_hyperparameters/" class="md-nav__link">
        Hyperparameters in Q-Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_x_sarsa/" class="md-nav__link">
        SARSA Algorithm: on-policy approach
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_xx_comments/" class="md-nav__link">
        Comments about Q-Learning and Sarsa implementation
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Using RL in non-deterministic environments
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Using RL in non-deterministic environments
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#trabalhe-com-o-arquivo-frozenlake_introductionpy" class="md-nav__link">
    Trabalhe com o arquivo FrozenLake_introduction.py
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabalhe-com-o-arquivo-frozenlakepy" class="md-nav__link">
    Trabalhe com o arquivo FrozenLake.py
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#e-o-algoritmo-sarsa" class="md-nav__link">
    E o algoritmo Sarsa?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#outro-mapa" class="md-nav__link">
    Outro mapa
  </a>
  
    <nav class="md-nav" aria-label="Outro mapa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algoritmo-e-hiperparametros-utilizados-para-o-treinamento" class="md-nav__link">
    Algoritmo e hiperparâmetros utilizados para o treinamento
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rubrica-de-avaliacao" class="md-nav__link">
    Rubrica de avaliação
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deadline" class="md-nav__link">
    Deadline
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#trabalhe-com-o-arquivo-frozenlake_introductionpy" class="md-nav__link">
    Trabalhe com o arquivo FrozenLake_introduction.py
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trabalhe-com-o-arquivo-frozenlakepy" class="md-nav__link">
    Trabalhe com o arquivo FrozenLake.py
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#e-o-algoritmo-sarsa" class="md-nav__link">
    E o algoritmo Sarsa?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#outro-mapa" class="md-nav__link">
    Outro mapa
  </a>
  
    <nav class="md-nav" aria-label="Outro mapa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algoritmo-e-hiperparametros-utilizados-para-o-treinamento" class="md-nav__link">
    Algoritmo e hiperparâmetros utilizados para o treinamento
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rubrica-de-avaliacao" class="md-nav__link">
    Rubrica de avaliação
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deadline" class="md-nav__link">
    Deadline
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  



<h1 id="using-rl-in-non-deterministic-environments">Using RL in non-deterministic environments</h1>
<p>O ambiente <a href="https://gymnasium.farama.org/environments/toy_text/frozen_lake/">Frozen Lake</a> é um ambiente não determinístico onde um agente deve encontrar um caminho do lugar onde ele está para outro lugar passando por buracos. Se ele chegar no objetivo sem cair no buraco então ele termina a tarefa e tem 1 ponto de reward. Se ele cair em um dos buracos então ele termina a tarefa com 0 pontos de reward. Cada ação que não leva para um estado terminal tem reward igual a 0.  </p>
<p>Neste ambiente o agente consegue executar 4 ações: ir para cima, ir para baixo, ir para esquerda e ir para direita. <strong>Como o chão é de gelo, não necessariamente a ação de ir para baixo vai levar o agente para baixo</strong>, por exemplo. Isto acontece com todas as quatro ações. Por isso que este ambiente é não determinístico.</p>
<h2 id="trabalhe-com-o-arquivo-frozenlake_introductionpy">Trabalhe com o arquivo <code>FrozenLake_introduction.py</code></h2>
<ol>
<li>
<p>Este arquivo está disponível em <a href="https://github.com/Insper/rl_code/tree/main/src/part_03">https://github.com/Insper/rl_code/tree/main/src/part_03</a>.</p>
</li>
<li>
<p>Leia a documentação do código fonte disponível em <a href="https://gymnasium.farama.org/environments/toy_text/frozen_lake/">https://gymnasium.farama.org/environments/toy_text/frozen_lake/</a></p>
</li>
<li>
<p>Veja o que está codificado no arquivo <code>FrozenLake_introduction.py</code> e execute o mesmo.</p>
</li>
<li>
<p>Quantos estados e quantas ações o ambiente FrozenLake-v1 tem?</p>
</li>
<li>
<p>O que aconteceu com a execução das ações? O resultado foi o esperado? Descreva o que aconteceu.</p>
</li>
</ol>
<h2 id="trabalhe-com-o-arquivo-frozenlakepy">Trabalhe com o arquivo <code>FrozenLake.py</code></h2>
<ul>
<li>
<p>Este arquivo também está em <a href="https://github.com/Insper/rl_code/tree/main/src/part_03">https://github.com/Insper/rl_code/tree/main/src/part_03</a></p>
</li>
<li>
<p>Abra em um editor de texto e descomente as linhas 12 e 13 e comente a linha 14. O código deve ficar como abaixo:</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># only execute the following lines if you want to create a new q-table</span>
<span class="n">qlearn</span> <span class="o">=</span> <span class="n">QLearning</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">epsilon_min</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">epsilon_dec</span><span class="o">=</span><span class="mf">0.9999</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">500000</span><span class="p">)</span>
<span class="n">q_table</span> <span class="o">=</span> <span class="n">qlearn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="s1">&#39;data/q-table-frozen-lake.csv&#39;</span><span class="p">,</span><span class="s1">&#39;results/actions_frozen_lake&#39;</span><span class="p">)</span>
<span class="c1">#q_table = loadtxt(&#39;data/q-table-frozen-lake.csv&#39;, delimiter=&#39;,&#39;)</span>
</code></pre></div>
<ul>
<li>Execute o arquivo <code>FrozenLake.py</code> com o comando:</li>
</ul>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>FrozenLake.py
</code></pre></div>
<ul>
<li>
<p>Agora faça o algoritmo <code>FrozenLake.py</code> ler a Q-table a partir do arquivo gerado anteriormente e veja qual é o comportamento. Execute diversas vezes. Ele consegue chegar ao objetivo sempre? Ele consegue chegar ao objetivo na maioria das vezes? </p>
</li>
<li>
<p>E se executarmos 100 vezes? Quantas vezes o agente consegue atingir o objetivo? Execute o comando abaixo:</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>FrozenLake100times.py
</code></pre></div>
<ul>
<li>
<p>Como podemos melhorar o desempenho deste agente?</p>
</li>
<li>
<p>Teste diferentes configurações de hiperparâmetros. Qual é o comportamento visto no gráfico de episódios versus rewards? </p>
</li>
</ul>
<h2 id="e-o-algoritmo-sarsa">E o algoritmo Sarsa?</h2>
<ul>
<li>
<p>Será que o algoritmo Sarsa tem um desempenho melhor para problemas não-determinísticos? </p>
</li>
<li>
<p>Em <a href="https://github.com/Insper/rl_code/tree/main/src/part_03">https://github.com/Insper/rl_code/tree/main/src/part_03</a> tem um arquivo chamado <code>FrozenLakeSarsa.py</code> que você pode utilizar para responder esta pergunta. </p>
</li>
</ul>
<h2 id="outro-mapa">Outro mapa</h2>
<p>Existem dois mapas pré-configurados em <a href="https://gymnasium.farama.org/environments/toy_text/frozen_lake/">https://gymnasium.farama.org/environments/toy_text/frozen_lake/</a>. O mapa 4x4 e um mapa 8x8. E se mudarmos o mapa para 8x8? </p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;FrozenLake-v1&quot;</span><span class="p">,</span> <span class="n">map_name</span><span class="o">=</span><span class="s2">&quot;8x8&quot;</span><span class="p">,</span> <span class="n">is_slippery</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">env</span>
</code></pre></div>
<ul>
<li>O que muda? O problema se torna mais complexo? É necessário mudar algum dos hiperparâmetros? Qual é o melhor algoritmo? <em>Sarsa</em> ou <em>Q-Learning</em>? </li>
</ul>
<p>Considere o seguinte objetivo: <em>desenvolver um agente capaz de chegar ao ponto final em mais de 80% das vezes". Faça o *clone</em> do projeto <a href="https://classroom.github.com/a/Ag-dCmlJ">https://classroom.github.com/a/Ag-dCmlJ</a>. Você deve adicionar neste projeto e fazer o commit dos seguintes artefatos: </p>
<ul>
<li>
<p>o arquivo <code>q-table.csv</code> dentro do diretório <code>data</code>. Já existe um arquivo q-table neste projeto, mas ele é para a versão do ambiente 4x4. Quando você executar o arquivo <code>test_frozenlake.py</code> usando o comando <code>pytest</code> irá ocorrer um erro de <code>IndexError</code>. Você deve substituir este arquivo pelo arquivo gerado pelo seu agente durante o período de treinamento; </p>
</li>
<li>
<p>depois de substituir o arquivo <code>data/q-table.csv</code>, você poderá executar os testes e verificar se o mesmo é aprovado em todos os testes. São quatro testes: o primeiro executa o ambiente 1000 vezes e verifica se o agente conseguiu chegar ao final em no mínimo 700 vezes. Os outros 3 testes fazem exatamente a mesma coisa: executam o agente no ambiente 1000 vezes e verificam se o agente conseguiu chegar ao final em no mínimo 800 vezes;</p>
</li>
<li>
<p>você também deve adicionar a sua implementação no diretório raiz deste projeto, e;</p>
</li>
<li>
<p>alterar o arquivo README.md informando os hiperparâmetros utilizados para o treinamento. </p>
</li>
<li>
<p>(critério para A+) apresentar um gráfico comparando a curva de aprendizagem de diversas abordagens utilizadas durante o treinamento. A imagem deste gráfico deve ser adicionada ao projeto e o texto explicando os resultados ao arquivo README.md.  </p>
</li>
</ul>
<h3 id="algoritmo-e-hiperparametros-utilizados-para-o-treinamento">Algoritmo e hiperparâmetros utilizados para o treinamento</h3>
<table>
<thead>
<tr>
<th align="left">Atributo</th>
<th align="center">Valor</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Algoritmo</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">alpha</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">gamma</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">epsilon</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">epsilon_dec</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">epsilon_min</td>
<td align="center"></td>
</tr>
<tr>
<td align="left">qtd_episodios</td>
<td align="center"></td>
</tr>
</tbody>
</table>
<h3 id="rubrica-de-avaliacao">Rubrica de avaliação</h3>
<ul>
<li>
<p>Deixou de entregar um dos artefatos: q-table, implementação na forma de arquivo python ou arquivo README.md atualizado com os hiperparâmetros: igual a <strong>Insuficiente (I)</strong> - nota 2. </p>
</li>
<li>
<p>Entregou todos os artefatos mencionados acima então a nota é calculada de acordo com o número de testes aprovados: </p>
<ul>
<li>1 teste aprovado = 2.5, </li>
<li>2 testes aprovados = 5.0, </li>
<li>3 testes aprovados = 7.5, </li>
<li>4 testes aprovados = 9.0</li>
</ul>
</li>
<li>
<p>Foi aprovado em todos os testes e entregou o gráfico comparando a curva de aprendizagem de diversas abordagens utilizadas ao longo do treinamento então nota igual a <strong>10 (dez)</strong>. </p>
</li>
</ul>
<h3 id="deadline">Deadline</h3>
<p>O deadline para a entrega desta atividade é 12 de março de 2023 às 23:30 horas. </p>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">March 9, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.db81ec45.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6df46069.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.0.0/js-yaml.min.js"></script>
      
        <script src="../../js/markdown-enhancer.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>