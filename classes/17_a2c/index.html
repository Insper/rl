
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://insper.github.io/rl/classes/17_a2c/">
      
      
        <link rel="prev" href="../17_reinforce/">
      
      
        <link rel="next" href="../15_xx_comments/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>A2C: Advantage Actor-Critic - Aprendizagem por Reforço</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2afb09e1.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#a2c-advantage-actor-critic" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Aprendizagem por Reforço" class="md-header__button md-logo" aria-label="Aprendizagem por Reforço" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Aprendizagem por Reforço
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              A2C: Advantage Actor-Critic
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Aprendizagem por Reforço" class="md-nav__button md-logo" aria-label="Aprendizagem por Reforço" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Aprendizagem por Reforço
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../goals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ementa
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../plan/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Plano
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../assessment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Avaliação
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Aulas
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Aulas
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Introdução
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            Introdução
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Apresentação da disciplina
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04_toolings_envs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ferramentas e ambientes para aprendizagem por reforço
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Q-Learning and Sarsa
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            Q-Learning and Sarsa
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_q_learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Algoritmo Q-Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_x_hyperparameters/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hiperparâmetros em Q-Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_xx_hyper_comments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Alguns comentários sobre as entregas
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_x_sarsa/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Algoritmo SARSA: abordagem on-policy
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_xx_comments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comentários sobre as implementações do Q-Learning e Sarsa
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ambientes e metodologias
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Ambientes e metodologias
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Como avaliar o desempenho de um agente?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06_non_determ/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ambientes não-determinísticos
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06_non_determ_comments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comentários sobre as entregas referentes ao ambiente Frozen Lake.
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09_more_complex/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Implementando um agente para lidar com um ambiente um pouco mais complexo
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Deep Q-Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            Deep Q-Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_deep_q_learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deep Reinforcement Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_deep_q_learning_lunar_lander/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lunar Lander Project
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Policy Optimization e Actor-Critic
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            Policy Optimization e Actor-Critic
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_reinforce/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Algoritmo Reinforce
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    A2C: Advantage Actor-Critic
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    A2C: Advantage Actor-Critic
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#vantagem" class="md-nav__link">
    <span class="md-ellipsis">
      Vantagem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#atividade" class="md-nav__link">
    <span class="md-ellipsis">
      Atividade
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    <span class="md-ellipsis">
      Referências
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias-adicionais" class="md-nav__link">
    <span class="md-ellipsis">
      Referências adicionais
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#entrega" class="md-nav__link">
    <span class="md-ellipsis">
      Entrega
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_xx_comments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comentários sobre as últimas implementações
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_ppo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Proximal Policy Optimization (PPO)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21_historia_reinforce_ppo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evolução do Reinforce ao PPO
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Projetos
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Projetos
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/projeto_intermediario/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Projeto intermediário
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/projeto_final/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Projeto Final
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Referências
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#vantagem" class="md-nav__link">
    <span class="md-ellipsis">
      Vantagem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#atividade" class="md-nav__link">
    <span class="md-ellipsis">
      Atividade
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias" class="md-nav__link">
    <span class="md-ellipsis">
      Referências
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referencias-adicionais" class="md-nav__link">
    <span class="md-ellipsis">
      Referências adicionais
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#entrega" class="md-nav__link">
    <span class="md-ellipsis">
      Entrega
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="a2c-advantage-actor-critic">A2C: Advantage Actor-Critic</h1>
<p>No artigo original de <a href="https://arxiv.org/abs/1602.01783">Mnih et al. (2016)</a>, os autores propõem um algoritmo de aprendizado por reforço chamado A2C (Advantage Actor-Critic). </p>
<p>O método de ator-critic é uma abordagem que combina um ator, que é responsável por escolher ações, e um crítico, que é responsável por avaliar as ações escolhidas. </p>
<center>
<img src="img/pseudo_a2c.png" alt="Pseudo código A2C" style="width:800px;"/>
</center>

<p>Uma forma visual de entender o funcionamento do algoritmo é apresentada abaixo: </p>
<center>
<img src="img/diagrama_a2c.png" alt="Diagrama A2C" style="width:500px;"/>
</center>

<p>Onde <strong>Actor</strong> é do tipo <em>policy gradient</em> e <strong>Critic</strong> é do tipo <em>value function</em> ou <em>value based</em>.</p>
<p>Os autores também propõe o conceito de vantagem, que é uma medida de quão melhor é uma ação em relação a outra. O uso deste conceito cria um <em>baseline</em> para a atualização da política, o que se mostrou eficiente para a convergência do algoritmo. </p>
<h2 id="vantagem">Vantagem</h2>
<p>A vantagem é calculada como a diferença entre o retorno esperado de uma ação e o valor do estado atual. </p>
<p><span class="arithmatex">\(Adv^{\pi}(s,a) = Q^{\pi}(s,a) - V^{\pi}(s)\)</span></p>
<ul>
<li>onde <span class="arithmatex">\(Q^{\pi}(s,a)\)</span> é o retorno esperado de uma ação <span class="arithmatex">\(a\)</span> em um estado <span class="arithmatex">\(s\)</span> seguindo uma política <span class="arithmatex">\(\pi\)</span>, </li>
<li>e <span class="arithmatex">\(V^{\pi}(s)\)</span> é o valor do estado <span class="arithmatex">\(s\)</span> seguindo a política <span class="arithmatex">\(\pi\)</span>.</li>
</ul>
<p>A vantagem pode ser entendida como quantificar o quanto mais alto é o retorno esperado ao aplicar a ação específica <span class="arithmatex">\(a\)</span> em comparação com seguir a política <span class="arithmatex">\(\pi\)</span> no estado <span class="arithmatex">\(s\)</span>.</p>
<p>A interpretação da vantagem pode ser usada para guiar a otimização da política. Para uma vantagem positiva, devemos aumentar a probabilidade da política <span class="arithmatex">\(\pi\)</span> selecionar a ação <span class="arithmatex">\(a\)</span> no estado <span class="arithmatex">\(s\)</span>; e devemos diminuir a probabilidade da política <span class="arithmatex">\(\pi\)</span> selecionar a ação <span class="arithmatex">\(a\)</span> no estado <span class="arithmatex">\(s\)</span> sempre que a vantagem for negativa.</p>
<h2 id="atividade">Atividade</h2>
<p>O objetivo desta atividade é compreender o funcionamento do algoritmo A2C e também praticar o uso de bibliotecas de aprendizado por reforço.</p>
<p>Utilize a implementação do A2C disponível na biblioteca <a href="https://pypi.org/project/stable-baselines3/">stable-baselines3</a> para treinar um agente que consegue atuar nos ambientes <a href="https://gymnasium.farama.org/environments/classic_control/cart_pole/">CartPole-v1</a>, <a href="https://gymnasium.farama.org/environments/box2d/lunar_lander/">LunarLander-v3</a> e <a href="https://ale.farama.org/environments/breakout/">Breakout</a>. </p>
<p>A implementação é direta. No entanto, exige alguns cuidados. A biblioteca stable-baseline3 possui o seu próprio ambiente. O escopo desta atividade não inclui o uso dos ambientes da biblioteca stable-baseline3. Você deve utilizar o ambiente Gymnasium para esta atividade.</p>
<p>Segue exemplo de código</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPO</span><span class="p">,</span> <span class="n">DQN</span><span class="p">,</span> <span class="n">A2C</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gymnasium</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gym</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3.common.logger</span><span class="w"> </span><span class="kn">import</span> <span class="n">configure</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">stable_baselines3.common.evaluation</span><span class="w"> </span><span class="kn">import</span> <span class="n">evaluate_policy</span>

<span class="n">tmp_path</span> <span class="o">=</span> <span class="s2">&quot;./results/&quot;</span>
<span class="n">new_logger</span> <span class="o">=</span> <span class="n">configure</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;stdout&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="s2">&quot;tensorboard&quot;</span><span class="p">])</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="n">policy</span> <span class="o">=</span> <span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">set_logger</span><span class="p">(</span><span class="n">new_logger</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">100_000</span><span class="p">)</span>

<span class="n">mean_reward</span><span class="p">,</span> <span class="n">std_reward</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">(),</span> <span class="n">n_eval_episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Mean reward: </span><span class="si">{</span><span class="n">mean_reward</span><span class="si">}</span><span class="s1"> +/- </span><span class="si">{</span><span class="n">std_reward</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;modelo treinado&#39;</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s1">&#39;human&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="n">obs</span><span class="p">,</span><span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_state</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
      <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</code></pre></div>
<ul>
<li>Entenda o funcionamento do código acima. </li>
<li>Analise os logs gerados. É possível a partir deste log criar as curvas de aprendizado?</li>
<li>O comportamento do agente treinado é adequado? </li>
<li>Leia a documentação em <a href="https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html">https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html</a> e tente modificar os hiperparâmetros do modelo para melhorar o desempenho do agente.</li>
<li>A mesma biblioteca possui uma implementação de DQN. A documentação está disponível em <a href="https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html">https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html</a>. Compare o desempenho do A2C com o DQN. Qual dos dois algoritmos é mais eficiente para resolver o problema do CartPole-v1, LunarLander-v2 e implementar um jogador para o Breakout?</li>
<li>No caso do DQN, use os mesmos hiperparâmetros de trabalhos anteriores. Assim será possível comparar o desempenho de implementações diferentes do DQN. Será que existe diferença entre as implementações do DQN?</li>
</ul>
<h2 id="referencias">Referências</h2>
<ul>
<li>
<p>Volodymyr Mnih, Adrià Puigdomènech Badia, Mehdi Mirza, Alex Graves, Tim Harley, Timothy P. Lillicrap, David Silver, and Koray Kavukcuoglu. 2016. <a href="https://arxiv.org/abs/1602.01783">Asynchronous methods for deep reinforcement learning</a>. In Proceedings of the 33<sup>rd</sup> International Conference on International Conference on Machine Learning - Volume 48 (ICML'16). JMLR.org, 1928–1937.</p>
</li>
<li>
<p>Antonin Raffin, Ashley Hill, Adam Gleave, Anssi Kanervisto, Maximilian Ernestus, and Noah Dormann. 2021. Stable-Baselines3: Reliable Reinforcement Learning Implementations. Journal of Machine Learning Research 22, 268 (2021), 1–8. Retrieved from <a href="http://jmlr.org/papers/v22/20-1364.html">http://jmlr.org/papers/v22/20-1364.html</a></p>
</li>
<li>
<p>OpenAI Baselines: ACKTR &amp; A2C. Disponível em <a href="https://openai.com/research/openai-baselines-acktr-a2c">https://openai.com/research/openai-baselines-acktr-a2c</a>.</p>
</li>
</ul>
<h2 id="referencias-adicionais">Referências adicionais</h2>
<p>Outros ambientes com implementações já prontas que podem ser úteis na implementação de outros projetos: </p>
<ul>
<li><a href="https://tianshou.org/en/stable/">https://tianshou.org/en/stable/</a></li>
<li><a href="https://marllib.readthedocs.io/en/latest/">https://marllib.readthedocs.io/en/latest/</a></li>
</ul>
<h2 id="entrega">Entrega</h2>
<p>O trabalho deve ser entregue no GitHub Classroom. O link para o repositório é <a href="https://classroom.github.com/a/jBOTFJJA">https://classroom.github.com/a/jBOTFJJA</a>.</p>
<p>Os artefatos que devem estar presentes no repositório são: </p>
<ul>
<li>o código fonte de todas as implementações (treinamento e uso do modelo), de preferência em um diretório único chamado <code>src</code>;</li>
<li>os arquivos de <em>log gerados</em> durante o treinamento e que foram usados para gerar as curvas de aprendizado, de preferência em um diretório único chamado <code>logs</code>;</li>
<li>um arquivo <code>requirements.txt</code> com as dependências do projeto;</li>
<li>um arquivo README.md que sumariza os principais achados do trabalho na raiz do projeto, e;</li>
<li>um diretório <code>models</code> com os modelos treinados.</li>
</ul>
<p>O deadline para a entrega desta atividade é 03 de abril de 2024 (quinta-feira) às 23:30 horas. Este trabalho deve ser feito em grupo com até 2 integrantes.</p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="March 26, 2025 13:13:32">March 26, 2025</span>
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.0.0/js-yaml.min.js"></script>
      
        <script src="../../js/markdown-enhancer.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>